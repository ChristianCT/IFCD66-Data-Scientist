{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Web-Scraping-Lab\" data-toc-modified-id=\"Web-Scraping-Lab-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Web Scraping Lab</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Useful-Resources\" data-toc-modified-id=\"Useful-Resources-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Useful Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-of-all,-gathering-our-tools.\" data-toc-modified-id=\"First-of-all,-gathering-our-tools.-1.0.1.1\"><span class=\"toc-item-num\">1.0.1.1&nbsp;&nbsp;</span>First of all, gathering our tools.</a></span></li><li><span><a href=\"#Challenge-1---Download,-parse-(using-BeautifulSoup),-and-print-the-content-from-the-Trending-Developers-page-from-GitHub:\" data-toc-modified-id=\"Challenge-1---Download,-parse-(using-BeautifulSoup),-and-print-the-content-from-the-Trending-Developers-page-from-GitHub:-1.0.1.2\"><span class=\"toc-item-num\">1.0.1.2&nbsp;&nbsp;</span>Challenge 1 - Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:</a></span></li><li><span><a href=\"#Display-the-names-of-the-trending-developers-retrieved-in-the-previous-step.\" data-toc-modified-id=\"Display-the-names-of-the-trending-developers-retrieved-in-the-previous-step.-1.0.1.3\"><span class=\"toc-item-num\">1.0.1.3&nbsp;&nbsp;</span>Display the names of the trending developers retrieved in the previous step.</a></span></li><li><span><a href=\"#Challenge-2---Display-the-trending-Python-repositories-in-GitHub\" data-toc-modified-id=\"Challenge-2---Display-the-trending-Python-repositories-in-GitHub-1.0.1.4\"><span class=\"toc-item-num\">1.0.1.4&nbsp;&nbsp;</span>Challenge 2 - Display the trending Python repositories in GitHub</a></span></li><li><span><a href=\"#Challenge-3---Display-all-the-image-links-from-Walt-Disney-wikipedia-page\" data-toc-modified-id=\"Challenge-3---Display-all-the-image-links-from-Walt-Disney-wikipedia-page-1.0.1.5\"><span class=\"toc-item-num\">1.0.1.5&nbsp;&nbsp;</span>Challenge 3 - Display all the image links from Walt Disney wikipedia page</a></span></li><li><span><a href=\"#Challenge-4---Retrieve-all-links-to-pages-on-Wikipedia-that-refer-to-some-kind-of-Python.\" data-toc-modified-id=\"Challenge-4---Retrieve-all-links-to-pages-on-Wikipedia-that-refer-to-some-kind-of-Python.-1.0.1.6\"><span class=\"toc-item-num\">1.0.1.6&nbsp;&nbsp;</span>Challenge 4 - Retrieve all links to pages on Wikipedia that refer to some kind of Python.</a></span></li><li><span><a href=\"#Challenge-5---Number-of-Titles-that-have-changed-in-the-United-States-Code-since-its-last-release-point\" data-toc-modified-id=\"Challenge-5---Number-of-Titles-that-have-changed-in-the-United-States-Code-since-its-last-release-point-1.0.1.7\"><span class=\"toc-item-num\">1.0.1.7&nbsp;&nbsp;</span>Challenge 5 - Number of Titles that have changed in the United States Code since its last release point</a></span></li><li><span><a href=\"#Challenge-6---A-Python-list-with-the-top-ten-FBI's-Most-Wanted-names\" data-toc-modified-id=\"Challenge-6---A-Python-list-with-the-top-ten-FBI's-Most-Wanted-names-1.0.1.8\"><span class=\"toc-item-num\">1.0.1.8&nbsp;&nbsp;</span>Challenge 6 - A Python list with the top ten FBI's Most Wanted names</a></span></li><li><span><a href=\"#Challenge-7---List-all-language-names-and-number-of-related-articles-in-the-order-they-appear-in-wikipedia.org\" data-toc-modified-id=\"Challenge-7---List-all-language-names-and-number-of-related-articles-in-the-order-they-appear-in-wikipedia.org-1.0.1.9\"><span class=\"toc-item-num\">1.0.1.9&nbsp;&nbsp;</span>Challenge 7 - List all language names and number of related articles in the order they appear in wikipedia.org</a></span></li><li><span><a href=\"#Challenge-8---A-list-with-the-different-kind-of-datasets-available-in-data.gov.uk\" data-toc-modified-id=\"Challenge-8---A-list-with-the-different-kind-of-datasets-available-in-data.gov.uk-1.0.1.10\"><span class=\"toc-item-num\">1.0.1.10&nbsp;&nbsp;</span>Challenge 8 - A list with the different kind of datasets available in data.gov.uk</a></span></li><li><span><a href=\"#Challenge-9---Top-10-languages-by-number-of-native-speakers-stored-in-a-Pandas-Dataframe\" data-toc-modified-id=\"Challenge-9---Top-10-languages-by-number-of-native-speakers-stored-in-a-Pandas-Dataframe-1.0.1.11\"><span class=\"toc-item-num\">1.0.1.11&nbsp;&nbsp;</span>Challenge 9 - Top 10 languages by number of native speakers stored in a Pandas Dataframe</a></span></li></ul></li><li><span><a href=\"#Stepping-up-the-game\" data-toc-modified-id=\"Stepping-up-the-game-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Stepping up the game</a></span><ul class=\"toc-item\"><li><span><a href=\"#Challenge-10---The-20-latest-earthquakes-info-(date,-time,-latitude,-longitude-and-region-name)-by-the-EMSC-as-a-pandas-dataframe\" data-toc-modified-id=\"Challenge-10---The-20-latest-earthquakes-info-(date,-time,-latitude,-longitude-and-region-name)-by-the-EMSC-as-a-pandas-dataframe-1.0.2.1\"><span class=\"toc-item-num\">1.0.2.1&nbsp;&nbsp;</span>Challenge 10 - The 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe</a></span></li><li><span><a href=\"#Challenge-11---IMDB's-Top-250-data-(movie-name,-Initial-release,-director-name-and-stars)-as-a-pandas-dataframe\" data-toc-modified-id=\"Challenge-11---IMDB's-Top-250-data-(movie-name,-Initial-release,-director-name-and-stars)-as-a-pandas-dataframe-1.0.2.2\"><span class=\"toc-item-num\">1.0.2.2&nbsp;&nbsp;</span>Challenge 11 - IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe</a></span></li><li><span><a href=\"#Challenge-12---Movie-name,-year-and-a-brief-summary-of-the-top-10-random-movies-(IMDB)-as-a-pandas-dataframe.\" data-toc-modified-id=\"Challenge-12---Movie-name,-year-and-a-brief-summary-of-the-top-10-random-movies-(IMDB)-as-a-pandas-dataframe.-1.0.2.3\"><span class=\"toc-item-num\">1.0.2.3&nbsp;&nbsp;</span>Challenge 12 - Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe.</a></span></li><li><span><a href=\"#Challenge-13---Find-the-live-weather-report-(temperature,-wind-speed,-description-and-weather)-of-a-given-city.\" data-toc-modified-id=\"Challenge-13---Find-the-live-weather-report-(temperature,-wind-speed,-description-and-weather)-of-a-given-city.-1.0.2.4\"><span class=\"toc-item-num\">1.0.2.4&nbsp;&nbsp;</span>Challenge 13 - Find the live weather report (temperature, wind speed, description and weather) of a given city.</a></span></li><li><span><a href=\"#Challenge-14---Book-name,price-and-stock-availability-as-a-pandas-dataframe.\" data-toc-modified-id=\"Challenge-14---Book-name,price-and-stock-availability-as-a-pandas-dataframe.-1.0.2.5\"><span class=\"toc-item-num\">1.0.2.5&nbsp;&nbsp;</span>Challenge 14 - Book name,price and stock availability as a pandas dataframe.</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Web Scraping\n",
    "\n",
    "Encontrarás en este cuaderno algunos ejercicios de web scraping para practicar tus habilidades de scraping usando `requests` y `Beautiful Soup`.\n",
    "\n",
    "**Consejos:**\n",
    "\n",
    "- Verifica el [código de estado de la respuesta](https://http.cat/) para cada solicitud para asegurarte de haber obtenido el contenido previsto.\n",
    "- Observa el código HTML en cada solicitud para entender el tipo de información que estás obteniendo y su formato.\n",
    "- Busca patrones en el texto de respuesta para extraer los datos/información solicitados en cada pregunta.\n",
    "- Visita cada URL y echa un vistazo a su fuente a través de Chrome DevTools. Necesitarás identificar las etiquetas HTML, nombres de clases especiales, etc., utilizados para el contenido HTML que se espera extraer.\n",
    "- Revisa los selectores CSS.\n",
    "\n",
    "### Recursos Útiles\n",
    "- Documentación de la [biblioteca Requests](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Doc de Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Lista de códigos de estado HTTP](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [Conceptos básicos de HTML](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [Conceptos básicos de CSS](https://www.cssbasics.com/#page_start)\n",
    "\n",
    "#### Primero que todo, reuniendo nuestras herramientas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Nuevamente, recuerda limitar tu salida antes de la entrega para que tu código no se pierda en la salida.**\n",
    "\n",
    "#### Desafío 1 - Descargar, analizar (usando BeautifulSoup) e imprimir el contenido de la página de Desarrolladores en Tendencia de GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_html=requests.get(url).text\n",
    "soup = BeautifulSoup(github_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muestra los nombres de los desarrolladores en tendencia recuperados en el paso anterior.\n",
    "\n",
    "Tu salida debe ser una lista de Python con los nombres de los desarrolladores. Cada nombre no debe contener ninguna etiqueta HTML.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1. Descubre la etiqueta HTML y los nombres de clase usados para los nombres de los desarrolladores. Puedes lograr esto usando Chrome DevTools.\n",
    "\n",
    "1. Usa BeautifulSoup para extraer todos los elementos HTML que contienen los nombres de los desarrolladores.\n",
    "\n",
    "1. Utiliza técnicas de manipulación de cadenas para reemplazar espacios en blanco y saltos de línea (es decir, `\\n`) en el *texto* de cada elemento HTML. Usa una lista para almacenar los nombres limpios.\n",
    "\n",
    "1. Imprime la lista de nombres.\n",
    "\n",
    "Tu salida debería lucir como abajo (con nombres diferentes):\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sebastian Raschka', 'Sanjay Viswanathan', 'Belleve', 'Matt Arsenault', 'Jonas Chevalier', 'Amir Raminfar', 'Stephen Celis', 'Mika Vilpas', 'sobolevn', \"Queen Vinyl Da.i'gyu-Kazotetsu\", 'Kevin Zakka', 'Clement Tsang', 'Lee Calcote', 'Micha Reiser', 'Eric Traut', 'Michael Davis', 'Mag Mell', '三咲雅 · Misaki Masa', 'Arthur Vickers', 'MinJae Kwon (Miti)', 'Singh', 'Alan Tse', 'Jess Frazelle', 'Trivikram Kamat', 'BIGTREETECH']\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar nombres limpios\n",
    "nombres = []\n",
    "\n",
    "# Encontrar todos los elementos que contienen los nombres de los desarrolladores\n",
    "nombres_html = soup.find_all('h1', class_='h3 lh-condensed')\n",
    "\n",
    "\n",
    "# Extraer y limpiar los nombres de los desarrolladores\n",
    "for nombre_html in nombres_html:\n",
    "    # Obtener el texto del elemento y limpiarlo\n",
    "    nombre = nombre_html.get_text(strip=True)\n",
    "    nombres.append(nombre)\n",
    "\n",
    "print(nombres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 2 - Mostrar los repositorios de Python en tendencia en GitHub\n",
    "\n",
    "Los pasos para resolver este problema son similares al anterior, excepto que necesitas encontrar los nombres de los repositorios en lugar de los nombres de los desarrolladores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'\n",
    "datos2 = requests.get(f\"{url2}\").text\n",
    "soup2 = BeautifulSoup(datos2, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opendatalab /MinerU', 'lllyasviel /stable-diffusion-webui-forge', 'lllyasviel /Fooocus', 'mingrammer /diagrams', 'yt-dlp /yt-dlp', 'hacs /integration', 'ollama /ollama-python', 'ytdl-org /youtube-dl', 'KurtBestor /Hitomi-Downloader', 'vinta /awesome-python', 'freqtrade /freqtrade', 'searxng /searxng', 'mahdibland /V2RayAggregator', 'home-assistant /operating-system', 'blakeblackshear /frigate', 'lipku /metahuman-stream', 'MustardChef /WSABuilds', 'openai /whisper']\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los nombres de los repos limpios\n",
    "repos = []\n",
    "\n",
    "# Encontrar todos los elementos que contienen los nombres de los repositorios\n",
    "repos_html = soup2.find_all('h2', class_='h3 lh-condensed')\n",
    "\n",
    "# Extraer y limpiar los nombres de los repos\n",
    "for repo_html in repos_html:\n",
    "    # Obtener el texto del elemento y limpiarlo\n",
    "    repo = repo_html.get_text(strip=True)\n",
    "    repos.append(repo)\n",
    "\n",
    "print(repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 3 - Mostrar todos los enlaces de imágenes de la página de Wikipedia de Walt Disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "disney = requests.get(f\"{url3}\").text\n",
    "soup3 = BeautifulSoup(disney, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https:/static/images/icons/wikipedia.png', 'https:/static/images/mobile/copyright/wikipedia-wordmark-en.svg', 'https:/static/images/mobile/copyright/wikipedia-tagline-en.svg', 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg/220px-Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Nuvola_apps_kaboodle.svg/16px-Nuvola_apps_kaboodle.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Disney_Oscar_1953_%28cropped%29.jpg/170px-Disney_Oscar_1953_%28cropped%29.jpg', 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/20px-Commons-logo.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/23px-Wikiquote-logo.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/26px-Wikisource-logo.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Disneyland_Resort_logo.svg/135px-Disneyland_Resort_logo.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/20px-Animation_disc.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/19px-P_vip.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Mickey_Mouse_colored_%28head%29.svg/20px-Mickey_Mouse_colored_%28head%29.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/19px-Video-x-generic.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/21px-Flag_of_Los_Angeles_County%2C_California.svg.png', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/21px-Blank_television_set.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/21px-Flag_of_the_United_States.svg.png', 'https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png', 'https:https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1', 'https:/static/images/footer/wikimedia-button.svg', 'https:/static/images/footer/poweredby_mediawiki.svg']\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los enlaces de las imágenes\n",
    "links_imagenes = []\n",
    "\n",
    "# Encontrar todos los elementos img en la página\n",
    "img_html = soup3.find_all('img')\n",
    "\n",
    "# Extraer y limpiar los enlaces de las imágenes\n",
    "for img in img_html:\n",
    "    # Obtener el valor del atributo src\n",
    "    src = img.get('src')\n",
    "    if src:\n",
    "        # Construir la url completa de la imagen\n",
    "        url_completa = f\"https:{src}\"\n",
    "        links_imagenes.append(url_completa)\n",
    "\n",
    "print(links_imagenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 4 - Recuperar todos los enlaces a páginas en Wikipedia que se refieren a algún tipo de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 ='https://en.wikipedia.org/wiki/Python' \n",
    "python = requests.get(f\"{url4}\").text\n",
    "soup4 = BeautifulSoup(python, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python', 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Python', 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Python', 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Python', 'https://en.wikipedia.orghttps://af.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://als.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://az.wikipedia.org/wiki/Python_(d%C9%99qiql%C9%99%C5%9Fdirm%C9%99)', 'https://en.wikipedia.orghttps://be.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)', 'https://en.wikipedia.orghttps://da.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://de.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://eu.wikipedia.org/wiki/Python_(argipena)', 'https://en.wikipedia.orghttps://fr.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://hr.wikipedia.org/wiki/Python_(razdvojba)', 'https://en.wikipedia.orghttps://id.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://ia.wikipedia.org/wiki/Python_(disambiguation)', 'https://en.wikipedia.orghttps://is.wikipedia.org/wiki/Python_(a%C3%B0greining)', 'https://en.wikipedia.orghttps://it.wikipedia.org/wiki/Python_(disambigua)', 'https://en.wikipedia.orghttps://la.wikipedia.org/wiki/Python_(discretiva)', 'https://en.wikipedia.orghttps://lb.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)', 'https://en.wikipedia.orghttps://nl.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)', 'https://en.wikipedia.orghttps://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)', 'https://en.wikipedia.orghttps://sk.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://sh.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://fi.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Python_(anlam_ayr%C4%B1m%C4%B1)', 'https://en.wikipedia.orghttps://vi.wikipedia.org/wiki/Python', 'https://en.wikipedia.orghttps://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)', 'https://en.wikipedia.org/wiki/Python', 'https://en.wikipedia.org/wiki/Talk:Python', 'https://en.wikipedia.org/wiki/Python', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit', 'https://en.wikipedia.org/w/index.php?title=Python&action=history', 'https://en.wikipedia.org/wiki/Python', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit', 'https://en.wikipedia.org/w/index.php?title=Python&action=history', 'https://en.wikipedia.org/wiki/Special:WhatLinksHere/Python', 'https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Python', 'https://en.wikipedia.org/w/index.php?title=Python&oldid=1233294168', 'https://en.wikipedia.org/w/index.php?title=Python&action=info', 'https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Python&id=1233294168&wpFormIdentifier=titleform', 'https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPython', 'https://en.wikipedia.org/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPython', 'https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Python&action=show-download-screen', 'https://en.wikipedia.org/w/index.php?title=Python&printable=yes', 'https://en.wikipedia.orghttps://commons.wikimedia.org/wiki/Category:Python', 'https://en.wikipedia.orghttps://en.wiktionary.org/wiki/Python', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=1', 'https://en.wikipedia.org/wiki/Pythonidae', 'https://en.wikipedia.org/wiki/Python_(genus)', 'https://en.wikipedia.org/wiki/Python_(mythology)', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=2', 'https://en.wikipedia.org/wiki/Python_(programming_language)', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=3', 'https://en.wikipedia.org/wiki/Python_of_Aenus', 'https://en.wikipedia.org/wiki/Python_(painter)', 'https://en.wikipedia.org/wiki/Python_of_Byzantium', 'https://en.wikipedia.org/wiki/Python_of_Catana', 'https://en.wikipedia.org/wiki/Python_Anghelo', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=4', 'https://en.wikipedia.org/wiki/Python_(Efteling)', 'https://en.wikipedia.org/wiki/Python_(Busch_Gardens_Tampa_Bay)', 'https://en.wikipedia.org/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=5', 'https://en.wikipedia.org/wiki/Python_(automobile_maker)', 'https://en.wikipedia.org/wiki/Python_(Ford_prototype)', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=6', 'https://en.wikipedia.org/wiki/Python_(missile)', 'https://en.wikipedia.org/wiki/Python_(nuclear_primary)', 'https://en.wikipedia.org/wiki/Colt_Python', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=7', 'https://en.wikipedia.org/wiki/Python_(codename)', 'https://en.wikipedia.org/wiki/Python_(film)', 'https://en.wikipedia.org/wiki/Monty_Python', 'https://en.wikipedia.org/wiki/Python_(Monty)_Pictures', 'https://en.wikipedia.org/w/index.php?title=Python&action=edit&section=8', 'https://en.wikipedia.orghttps://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0', 'https://en.wikipedia.orghttps://en.wikipedia.org/w/index.php?title=Python&oldid=1233294168', 'https://en.wikipedia.org//en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile']\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los enlaces relacionados con Python\n",
    "links_python = []\n",
    "\n",
    "# Encontrar todos los elementos a en la página\n",
    "a_html = soup4.find_all('a', href=True)\n",
    "\n",
    "# Filtrar y limpiar los enlaces que contienen 'Python'\n",
    "for a in a_html:\n",
    "    href = a.get('href')\n",
    "    text = a.get_text()\n",
    "    if 'Python' in text or 'Python' in href:\n",
    "        # Construir la URL completa de la página\n",
    "        url_completa = f\"https://en.wikipedia.org{href}\"\n",
    "        links_python.append(url_completa)\n",
    "\n",
    "print(links_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 5 - Número de Títulos que han cambiado en el Código de los Estados Unidos desde su último punto de lanzamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "\n",
    "# Obtener contenido html de la página y Parsear con BeautifulSoup\n",
    "codigo_usa = requests.get(url).text\n",
    "soup = BeautifulSoup(codigo_usa, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de títulos que han cambiado: 52\n",
      "['All titles in the format selected compressed into a zip archive.', '', 'Title 1 - General Provisions٭', 'Title 2 - The Congress', 'Title 3 - The President٭', 'Title 4 - Flag and Seal, Seat of Government, and the States٭', 'Title 5 - Government Organization and Employees٭', 'Title 6 - Domestic Security', 'Title 7 - Agriculture', 'Title 8 - Aliens and Nationality', 'Title 9 - Arbitration٭', 'Title 10 - Armed Forces٭', 'Title 11 - Bankruptcy٭', 'Title 12 - Banks and Banking', 'Title 13 - Census٭', 'Title 14 - Coast Guard٭', 'Title 16 - Conservation', 'Title 17 - Copyrights٭', 'Title 18 - Crimes and Criminal Procedure٭', 'Title 19 - Customs Duties', 'Title 20 - Education', 'Title 21 - Food and Drugs', 'Title 23 - Highways٭', 'Title 24 - Hospitals and Asylums', 'Title 25 - Indians', 'Title 26 - Internal Revenue Code', 'Title 27 - Intoxicating Liquors', 'Title 28 - Judiciary and Judicial Procedure٭', 'Title 29 - Labor', 'Title 30 - Mineral Lands and Mining', 'Title 31 - Money and Finance٭', 'Title 32 - National Guard٭', 'Title 33 - Navigation and Navigable Waters', 'Title 34 - Crime Control and Law Enforcement', 'Title 35 - Patents٭', 'Title 36 - Patriotic and National Observances, Ceremonies, and Organizations٭', 'Title 37 - Pay and Allowances of the Uniformed Services٭', \"Title 38 - Veterans' Benefits٭\", 'Title 39 - Postal Service٭', 'Title 40 - Public Buildings, Property, and Works٭', 'Title 41 - Public Contracts٭', 'Title 43 - Public Lands', 'Title 44 - Public Printing and Documents٭', 'Title 45 - Railroads', 'Title 46 - Shipping٭', 'Title 47 - Telecommunications', 'Title 48 - Territories and Insular Possessions', 'Title 49 - Transportation٭', 'Title 51 - National and Commercial Space Programs٭', 'Title 52 - Voting and Elections', 'Title 53 [Reserved]', 'Title 54 - National Park Service and Related Programs٭']\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los títulos que han cambiado\n",
    "titulos_cambiados = []\n",
    "\n",
    "# Encontrar todos los elementos que contienen información sobre cambios\n",
    "cambios_html = soup.find_all('div', class_='usctitle')\n",
    "\n",
    "# Extraer y limpiar los títulos de los cambios\n",
    "for cambio in cambios_html:\n",
    "    # Obtener el texto del elemento y limpiarlo\n",
    "    titulo = cambio.get_text(strip=True)\n",
    "    titulos_cambiados.append(titulo)\n",
    "\n",
    "print(f\"Número de títulos que han cambiado: {len(titulos_cambiados)}\")\n",
    "print(titulos_cambiados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 6 - Una lista de Python con los diez nombres más buscados por el FBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url7 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = requests.get(f\"{url7}\").text\n",
    "soup7 = BeautifulSoup(wanted, 'html.parser')\n",
    "wantedtag = soup7.find_all('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los nombres de los diez más buscados por FBI\n",
    "nombresfbi = []\n",
    "\n",
    "# Encontrar todos los elementos <h3> en la página\n",
    "wantedtag = soup7.find_all('h3', class_='title')\n",
    "\n",
    "# Extraer y limpiar los nombres de los más buscados\n",
    "for tag in wantedtag[:10]:  # Asegurarse de obtener solo los primeros diez nombres\n",
    "    # Obtener el texto del elemento y limpiarlo\n",
    "    nombre = tag.get_text(strip=True)\n",
    "    nombresfbi.append(nombre)\n",
    "\n",
    "# Imprimir la lista de los nombres de los más buscados\n",
    "print(nombresfbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 7 - Listar todos los nombres de idiomas y el número de artículos relacionados en el orden en que aparecen en wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url8 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = requests.get(f\"{url8}\").text\n",
    "soup8 = BeautifulSoup(languages, 'html.parser')\n",
    "langlist = soup8.find_all(\"div\", {\"class\": f\"central-featured-lang\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: 6,847,000+articles\n",
      "æ¥æ¬èª: 1,421,000+è¨äº\n",
      "Deutsch: 2.924.000+Artikel\n",
      "Ð ÑÑÑÐºÐ¸Ð¹: 1Â 987Â 000+ÑÑÐ°ÑÐµÐ¹\n",
      "EspaÃ±ol: 1.965.000+artÃ­culos\n",
      "FranÃ§ais: 2â¯621â¯000+articles\n",
      "ä¸­æ: 1,429,000+æ¡ç® / æ¢ç®\n",
      "Italiano: 1.871.000+voci\n",
      "ÙØ§Ø±Ø³Û: Û±Ù¬Û°Û°Û¶Ù¬Û°Û°Û°+ÙÙØ§ÙÙ\n",
      "PortuguÃªs: 1.128.000+artigos\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los nombres de idiomas y el número de artículos\n",
    "idiomas_articulos = []\n",
    "# Extraer y limpiar los nombres de idiomas y el número de artículos\n",
    "for lang in langlist:\n",
    "    idioma = lang.find('strong').get_text(strip=True)\n",
    "    num_articulos = lang.find('small').get_text(strip=True)\n",
    "    idiomas_articulos.append((idioma, num_articulos))\n",
    "\n",
    "for idioma, num_articulos in idiomas_articulos:\n",
    "    print(f\"{idioma}: {num_articulos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 8 - Una lista con los diferentes tipos de conjuntos de datos disponibles en data.gov.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url82 = 'https://data.gov.uk/'\n",
    "dats = requests.get(f\"{url82}\")\n",
    "soup8 = BeautifulSoup(dats.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cookies to collect information', 'View cookies', 'change your cookie settings', 'Business and economy', 'Crime and justice', 'Defence', 'Education', 'Environment', 'Government', 'Government spending', 'Health', 'Mapping', 'Society', 'Towns and cities', 'Transport', 'Digital service performance', 'Government reference data']\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los diferentes tipos de conjuntos de datos\n",
    "tipos_conjuntos_datos = []\n",
    "\n",
    "# Encontrar todos los elementos que contienen los tipos que están etiquetas a\n",
    "dataset_tags = soup8.find_all('a', class_='govuk-link')\n",
    "\n",
    "# Extraer y limpiar los tipos de conjuntos de datos\n",
    "for tag in dataset_tags:\n",
    "    tipo = tag.get_text(strip=True)\n",
    "    tipos_conjuntos_datos.append(tipo)\n",
    "\n",
    "print(tipos_conjuntos_datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 9 - Los 10 idiomas con más hablantes nativos almacenados en un DataFrame de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url9 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "tenlang = requests.get(url9)\n",
    "soup9 = BeautifulSoup(tenlang.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Idioma Hablantes nativos\n",
      "0  Mandarin Chinese             12.3%\n",
      "1           Spanish              6.0%\n",
      "2           English              5.1%\n",
      "3            Arabic              5.1%\n",
      "4             Hindi              3.5%\n",
      "5           Bengali              3.3%\n",
      "6        Portuguese              3.0%\n",
      "7           Russian              2.1%\n",
      "8          Japanese              1.7%\n",
      "9   Western Punjabi              1.3%\n"
     ]
    }
   ],
   "source": [
    "# Encontrar la tabla que contiene los datos de los idiomas\n",
    "tabla_idiomas = soup9.find('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "# Lista para almacenar los datos de idiomas\n",
    "idiomas_data = []\n",
    "\n",
    "# Extraer las filas de la tabla\n",
    "filas = tabla_idiomas.find_all('tr')\n",
    "\n",
    "# Recorrer las filas y extraer los datos\n",
    "for fila in filas[1:11]:  # Excluir la primera fila (cabecera) y limitar a las primeras 10 filas\n",
    "    columnas = fila.find_all('td')\n",
    "    if len(columnas) >= 3:\n",
    "        idioma = columnas[1].get_text(strip=True)\n",
    "        hablantes = columnas[2].get_text(strip=True)\n",
    "        idiomas_data.append({'Idioma': idioma, 'Hablantes nativos': hablantes})\n",
    "\n",
    "# Crear df con los datos de los idiomas\n",
    "df_idiomas = pd.DataFrame(idiomas_data)\n",
    "\n",
    "print(df_idiomas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subiendo el nivel\n",
    "#### Desafío 10 - La información de los 20 últimos terremotos (fecha, hora, latitud, longitud y nombre de la región) por el EMSC como un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\"><head><meta charset=\"utf-8\"/><meta content=\"srFzNKBTd0FbRhtnzP--Tjxl01NfbscjYwkp4yOWuQY\" name=\"google-site-verification\"><meta content=\"BCAA3C04C41AE6E6AFAF117B9469C66F\" name=\"msvalidate.01\"/><meta content=\"43b36314ccb77957\" name=\"y_key\"/><meta content=\"all\" name=\"robots\"/><meta content=\"earthquakes today - recent and latest earthquakes, earthquake map and earthquake information. Earthquake information for europe. EMSC (European Mediterranean Seismological Centre) provides real time earthquake information for seismic events with magnitude larger than 5 in the European Mediterranean area and larger than 7 in the rest of the world.\" lang=\"en\" name=\"description\"/><meta content=\"705855916142039\" property=\"fb:app_id\"/><meta content=\"en_FR\" property=\"og:locale\"/><meta content=\"website\" property=\"og:type\"/><meta content=\"EMSC - European-Mediterranean Seismological Centre\" property=\"og:site_name\"/><meta content=\"//www.emsc-csem.org/\" property=\"og:url\"/><link href=\"/favicon.png\" rel=\"icon\" type=\"image/x-icon\"/>\n",
       "<title>EMSC - European-Mediterranean Seismological Centre</title>\n",
       "<script> console.log((new Date()).toString());</script><link href=\"https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.css\" rel=\"stylesheet\"/><link href=\"//static3.emsc.eu/Css/m_emsc.min.css?v=2\" rel=\"stylesheet\"/><script src=\"//static1.emsc.eu/javascript/jquery-3.6.0.min.js\"></script><script> var emsc_ws_url=\"wss://cobra.emsc-csem.org/home\";</script><script src=\"https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.js\"></script><script src=\"//static1.emsc.eu/javascript/home.min.js?v=2\"></script><script src=\"//static2.emsc.eu/javascript/src/home_mapmember.js\"></script><script src=\"//static2.emsc.eu/javascript/emsc.min.js\"></script><style>.bg-HOME{width:100px;height:97px;background:url(//static1.emsc.eu/Css/img/home_sprites.png);display:inline-block}.bg-HOME_app{background-position:-103px -1px}.bg-HOME_queries{background-position:-1px -1px}.bg-HOME_searching{background-position:-1px -100px}.bg-HOME_felt_button{width:30px;height:29px;background-position:-103px -100px}.hleft{width:35%;display:inline-block}.quacc{border-left:8px solid rgb(179,0,18);padding-left:10px;margin-bottom:60px}.qusea-icon{width:100px;height:100px;margin:auto}.qusearch{display:inline-block;width:32%;text-align:center;vertical-align:top}.qusearch a{color:rgb(179,0,18);text-decoration:none}.qusea-label{padding:10px 0}.quacclab{font-weight:bold;font-size:26px;padding-bottom:5px}.qacc{font-weight:bold}#map_emsc_members{width:100%;height:320px;border:1px solid grey}.quacc:last-child{padding-right:20px}.news a div{text-align:left}.news .qusea-date{color:rgb(166,166,166);font-size:14px;font-style:italic;margin:0 5px}.news .qusea-label{color:rgb(0,0,0);font-size:14px;margin:0 5px}.qusea-icon.intensmap{position:relative;overflow:hidden;width:90%}.qusea-icon.intensmap img{position:absolute;top:-9999px;bottom:-9999px;left:-9999px;right:-9999px;margin:auto}.hright{width:62%;display:inline-block;float:right}.hmap{height:300px;border:1px solid black;margin-bottom:20px}.home_t2{font-weight:bold;width:50%;font-size:20px;display:inline-block;vertical-align:middle}.t2_hfe{text-align:right}.hfe{display:inline-flex;vertical-align:middle;line-height:normal}.home_felt{padding-left:20px;color:rgb(179,0,18)}.htab{position:relative}.table-scroll tbody{position:absolute;overflow-y:scroll;overflow-x:hidden;height:600px;margin-right:-10px}.table-scroll tr{width:100%;table-layout:fixed;display:inline-table}.table-scroll thead>tr>th{border:0;border-bottom:2px solid}.table-scroll th.thico{border-bottom:0}.table-scroll thead>tr>th,.table-scroll tbody>tr>td{padding:15px 3px;overflow:hidden}.table-scroll tbody{scrollbar-color:#F08080 #eee;scrollbar-width:thin}.table-scroll tbody::-webkit-scrollbar{width:10px}.table-scroll tbody::-webkit-scrollbar-track{background-color:#eee}.table-scroll tbody::-webkit-scrollbar-thumb{background-color:#F08080;background-clip:content-box}.table-scroll tbody::-webkit-scrollbar-thumb:hover{background-color:#a8bbbf}.htab table{width:100%}.htab table.eqs td{padding:8px 3px;font-size:14px}.tbmag{text-align:center}.tblat,.tblon,.tbdep{text-align:right}.tbreg{width:40%;text-align:left;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tbdat{width:20%;text-align:left}.tbdep{padding-right:15px!important}.lilist:hover,.lilist.hover{border:1px solid #eee;font-weight:bold;cursor:pointer}.tago{text-align:center;font-size:10px;color:grey}.leaf-evid-mag{font-weight:bold}.content{font-size:16px}.evtyp{width:26px;height:26px;background:url(//static2.emsc.eu/Css/img/sprites_eqtype.png);float:right;margin:1px;padding:0;display:inline-block}.bg-type_sonicboom{background-position:-29px -1px}.bg-type_volcano{background-position:-1px -1px}.bg-type_explosion{background-position:-113px -1px}.bg-type_landslide{background-position:-141px -1px}.bg-type_induced{background-position:-57px -1px}.bg-type_tsunami_pending{background-position:-169px -1px}.bg-type_tsunami{background-position:-197px -1px}.bg-type_tsunami_NO{background-position:-85px -1px}.htab{margin-left:-60px}.htab table.eqs td.tbico{padding:0;width:60px}.eqs thead>tr>th.thico{padding:0;margin:0;width:60px}.eqs{border-spacing:0}.eqs tbody{width:100%}.eqs tbody>tr{width:inherit;position:relative;display:table}.eqs thead>tr>th{padding:15px 1px;text-align:center}.eqs thead>tr>th.tbreg{text-align:left}.tbdat{text-align:center}.eqs tr:nth-child(2n){background:#ccc}.eqs td.tbico{background:white}.eqs th>div{font-size:small}.eqs tr.rw,.eqs tr.bow{font-weight:bold}.eqs tr.rw,tr.rw .tbdat a{color:red}.feltbt{background-color:rgb(179,0,18);padding:15px;border-radius:5px;cursor:pointer}.feltbt .home_felt{color:white}.ht20{font-size:26px}.lds-dual-ring{left:65%;margin-left:-40px;display:inline-block;width:80px;height:80px;position:absolute}.lds-dual-ring:after{content:\" \";display:block;width:64px;height:64px;margin:8px;border-radius:50%;border:6px solid #000;border-color:#000 transparent #000 transparent;animation:lds-dual-ring 1.2s linear infinite}@keyframes lds-dual-ring{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}.tbdat a{text-decoration:none;color:black}th\n",
       "@media (max-width:1270px){.content{margin:20px 5%}.eqs{font-size:14px}}.citiz{width:80px}.dm{display:inline-block;width:50%;margin-top:3px;text-align:center}.dm.comm:after,.dm.pic:after{width:16px;height:16px;background:url(//static3.emsc.eu/Images/icon/sprite_com_pic.png);display:block;content:\"\";margin:auto}.dm.comm:after{background-position:-19px -1px}.dm.pic:after{background-position:-1px -1px}.htab table.eqs td.tdcom{padding-left:5px}.hright2{margin-top:610px}.leaflet-bar a{background-color:#fff;border-bottom:1px solid #ccc;color:#444;display:block;height:26px;width:26px;line-height:1.45!important;text-align:center;text-decoration:none;font:bold 22px \"Lucida Console\",Monaco,monospace}.legend{box-sizing:border-box;border:2px solid #8c8c8c;padding:10px;text-align:left;margin:0 auto;background-color:white}.legend .title{text-align:center;font-size:16px;font-weight:bold}.dot{height:8px;width:8px;border-radius:50%;display:inline-block;vertical-align:middle}.dot.active{background:rgba(179,0,18,.4);border:4px solid rgba(179,0,18,1.00)}.dot.rights{background:rgba(231,167,167,.4);border:4px solid rgba(231,167,167,1.00)}.dot.nodal{background:rgba(0,0,0,.4);border:4px solid rgba(0,0,0,1.00)}.square_icon_active{width:20px;height:20px;background-color:rgba(179,0,18,.40);border:2px solid rgba(179,0,18,1.00)}.square_icon_nodal{width:20px;height:20px;background-color:rgba(0,0,0,.40);border:2px solid rgba(0,0,0,1.00)}.square_icon_rights{width:20px;height:20px;background-color:rgba(231,167,167,.4);;border:2px solid rgba(231,167,167,1.00)}.box{display:inline-block;margin:0 5px}.box:before{content:\"\";width:10px;height:10px;vertical-align:center;margin:0 4px -10%;display:inline-block}.rights:before{background-color:rgba(231,167,167,.4);;border:2px solid rgba(231,167,167,1.00)}.active:before{background-color:rgba(179,0,18,.40);border:2px solid rgba(179,0,18,1.00)}.nodal:before{background-color:rgba(0,0,0,.40);border:2px solid rgba(0,0,0,1.00)}</style></meta></head><body><div class=\"banner\" role=\"banner\"><div class=\"banner-ct\"><div class=\"bann-logo\">\n",
       "<a href=\"/\">\n",
       "<div class=\"spe emsc-logo\"></div>\n",
       "<div class=\"emsc-logo-label\">Centre Sismologique Euro-Méditerranéen</div>\n",
       "<div class=\"emsc-logo-label\">Euro-Mediterranean Seismological Centre</div>\n",
       "</a>\n",
       "</div><div class=\"hmenu\"><div class=\"hmenu0 hmenu1\"><div class=\"hmenus menut mt1\">Earthquakes</div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/Earthquake_map/\">World map</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/Earthquake_information/\">Latest earthquakes</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/Earthquake_data/\">Seismic data</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/Special_reports/\">Special reports</a></div></div><div class=\"hmenu0 hmenu2\"><div class=\"hmenus menut mt2\">LastQuake</div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/lastquake/how_it_works/\">How it works</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/lastquake/information_channels/\">Information channels</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/lastquake/citizen_seismology/\">Citizen seismology</a></div></div><div class=\"hmenu0 hmenu3\"><div class=\"hmenus menut mt3\">About Us</div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/about_us/who_we_are/\">Who we are</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/about_us/what_we_do/\">What we do</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/about_us/timeline/\">Timeline</a></div></div><div class=\"hmenu0 hmenu4\"><div class=\"hmenus menut mt4\">Partner with us</div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/partner_with_us/mission_and_vision/\">Mission &amp; vision</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/partner_with_us/partners/\">Partners</a></div><div class=\"hmenus menus\"><a href=\"//www.emsc-csem.org/partner_with_us/support_our_work/\">Support our work</a></div></div></div><div class=\"btncont\"><a class=\"hbt hbtdonate\" href=\"/donate/\">Donate</a><a class=\"hbt hbtlogin\" href=\"/Member/login.php\">Log in</a></div></div>\n",
       "<div class=\"emsctime\"></div>\n",
       "</div><div class=\"bandeau\"><div class=\"bandeaumv\"></div></div><div class=\"content\" role=\"main\"><div class=\"hleft\"><div class=\"quacc\">\n",
       "<div class=\"quacclab\">🎉 50<sup>th</sup> anniversary 🎉</div>\n",
       "<p>\n",
       "\t\t Join us in celebrating our 50<sup>th</sup> anniversary by leaving your testimony in our <a href=\"/about_us/guestbook\">guestbook</a>. \n",
       "        </p>\n",
       "</div><div class=\"quacc\">\n",
       "<div class=\"quacclab\">New Activity Report</div>\n",
       "<p>\n",
       "\t\tDiscover the achievements and milestones of the past year in our <a href=\"/Doc/EMSC_DOCS/EMSC_RT_activities_2023.pdf\" target=\"_blank\"> EMSC 2023 Activity Report</a>. \n",
       "\t\t</p>\n",
       "</div><div class=\"quacc\">\n",
       "<div class=\"quacclab\">Quick access</div>\n",
       "<div class=\"qusearch\"><a href=\"/Earthquake_information/\"><div class=\"qusea-icon\"><span class=\"bg-HOME bg-HOME_searching\"></span></div><div class=\"qusea-label qacc\">Search for earthquakes</div></a></div>\n",
       "<div class=\"qusearch\"><a href=\"/Earthquake_data/Data_queries.php\"><div class=\"qusea-icon\"><span class=\"bg-HOME bg-HOME_queries\"></span></div><div class=\"qusea-label qacc\">Data queries</div></a></div>\n",
       "<div class=\"qusearch\"><a href=\"/lastquake/information_channels/lastquake_app/\"><div class=\"qusea-icon\"><span class=\"bg-HOME bg-HOME_app\"></span></div><div class=\"qusea-label qacc\">Android &amp; iOS app</div></a></div>\n",
       "</div><div class=\"quacc\">\n",
       "<div class=\"quacclab\">Earthquake news</div><div class=\"qusearch news\"><a href=\"/Earthquake_information/earthquake.php?id=1689178\"><div class=\"qusea-icon intensmap\"><img alt=\"intensity map\" src=\"/Images/FELTREPORTS/168/1689178/IntensityMap.png\"/></div><div class=\"qusea-date\">Mon, 29 Jul 2024 20:00</div><div class=\"qusea-label\">Magnitude 4.9 earthquake in  Barstow Heights, United States</div></a></div><div class=\"qusearch news\"><a href=\"/Earthquake_information/earthquake.php?id=1688555\"><div class=\"qusea-icon intensmap\"><img alt=\"intensity map\" src=\"/Images/FELTREPORTS/168/1688555/IntensityMap.png\"/></div><div class=\"qusea-date\">Sun, 28 Jul 2024 04:35</div><div class=\"qusea-label\">Magnitude 5.1 earthquake in  Kon Tum, Vietnam</div></a></div><div class=\"qusearch news\"><a href=\"/Earthquake_information/earthquake.php?id=1686736\"><div class=\"qusea-icon intensmap\"><img alt=\"intensity map\" src=\"/Images/FELTREPORTS/168/1686736/IntensityMap.png\"/></div><div class=\"qusea-date\">Wed, 24 Jul 2024 00:42</div><div class=\"qusea-label\">Magnitude 4.4 earthquake in  Durrës, Albania</div></a></div></div><script> var memb = {\"categories\":{\"nodal\":\"Key nodal members\",\"rights\":\"Members by right\",\"active\":\"Active members\"},\"lists\":{\"active\":{\"41.3275_19.81889\":[\"IGEO: Institute of Geosciences  (Tirana - Albania) - Contact: Dr. E. DUSHI\"],\"36.73225_3.08746\":[\"CRAAG: Centre de Recherche en Astronomie, Astrophysique et Geophysique  (Algiers - Algeria) - Contact: Dr. H. BELDJOUDI\"],\"40.18111_44.51361\":[\"NSSP: National Survey for Seismic Protection  (Yerevan - Armenia) - Contact: Dr. S. MARGARYAN\"],\"48.20849_16.37208\":[\"GSA: GeoSphere Austria (Vienna - Austria) - Contact: DI Helmut HAUSMANN \"],\"40.366656_49.835183\":[\"RSSC: Republican Seismic Survey Center of Azerbaijan National Academy of Sciences (Baku - Azerbaijan) - Contact: Dr. G.J.YETIRMISHLI\"],\"53.9_27.56667\":[\"CGM: Center of Geophysical Monitoring  (Minsk - Belarus) - Contact: \\tDr. V. ARONOV\"],\"50.85045_4.34878\":[\"ORB\\/ROB: Royal Observatory of Belgium  (Brussels - Belgium) - Contact: Dr. F. COLLIN\"],\"43.84864_18.35644\":[\"FMI: Federal Meteorological Institute  (Sarajevo - Bosnia and Herzegovina) - Contact: \\tM. GENJAC\"],\"44.77842_17.19386\":[\"RHI: Republic Hydrometeorological Institute  (Banja Luka - Bosnia and Herzegovina) - Contact: \\tDr. S. CVIJIC-AMULIC\"],\"42.69751_23.32415\":[\"NIGGG: National Institute in Geophysics, Geodesy and Geography - BAS (Sofia - Bulgaria) - Contact: \\tAss. Prof. PLAMENA RAYKOVA\"],\"45.81444_15.97798\":[\"AMGI & CSS: Andrija Mohorovicic Geophysical Institute and Croatian Seismological Survey  (Zagreb - Croatia) - Contact: \\tI. IVANCIC\"],\"35.17531_33.3642\":[\"GSD: Geological Survey Department  (Nicosia - Cyprus) - Contact: C. CHATZIGEORGIOU\"],\"49.19522_16.60796\":[\"IPE: Institute of Physics of the Earth, Brno  (Brno - Czech Republic) - Contact: \\tDr. P. SPACEK\"],\"50.08804_14.42076\":[\"GFU: Geophysical Institute of the Academy of Sciences  (Prague - Czech Republic) - Contact: \\tDr. J. ZEDNIK\"],\"55.67594_12.56553\":[\"GEUS: Geological Survey of Denmark and Greenland  (Copenhagen - Denmark) - Contact: Dr. P. VOSS\"],\"11.58901_43.14503\":[\"CERD: Observatoire Geophysique d'Arta  (Djibouti - Djibouti) - Contact: SAAD IBRAHIM\"],\"30.06263_31.24967\":[\"NRIAG: National Research Institute of Astronomy and Geophysics  (Cairo - Egypt) - Contact: Prof. Sherif Elhady\"],\"60.16952_24.93545\":[\"ISF: Institute of Seismology (Helsinki - Finland) - Contact: Dr T. TIIRA\"],\"45.17869_5.71479\":[\"ISTerre: ISTerre, Institut des Sciences de la Terre (Grenoble - France) - Contact: \\tDr. P. GUEGUEN\"],\"48.58392_7.74553\":[\"BCSF: Bureau Central Sismologique Francais  (Strasbourg - France) - Contact: Dr. F. MASSON\"],\"41.69411_44.83368\":[\"SMC: Seismic Monitoring Centre of Georgia  (Tbilisi - Georgia) - Contact: \\tDr. T. GODOLADZE\"],\"52.52437_13.41053\":[\"BGR: Federal Institute for Geosciences and Natural Resources  (Berlin - Germany) - Contact: Dr. K. STAMMLER\"],\"37.98376_23.72784\":[\"NOA: National Observatory of Athens (Athens - Greece) - Contact: \\tDr. A. TSELENTIS\"],\"38.24444_21.73444\":[\"UPSL: Laboratory of Seismology, University of Patras (Patra - Greece) - Contact: \\tDr. E. SOKOS\"],\"40.64361_22.93086\":[\"ITSAK: Institute of Engineering Seismology and Earthquake Engineering  (Thessaloniki - Greece) - Contact: Dr. C. PAPAIOANNOU\",\"AUTH: University of Thessaloniki  (Thessaloniki - Greece) - Contact: \\tDr. E. SCORDILIS\"],\"47.49835_19.04045\":[\"BUD: HUN-REN EPSS K\\u00f6vesligethy Rad\\u00f3 Seismological Observatory (Budapest - Hungary) - Contact: B\\u00e1lint S\\u00fcle\"],\"64.13548_-21.89541\":[\"IMO: Icelandic Meteorological Office  (Reykjav\\u00edk - Iceland) - Contact: \\tDr. G. GUDMUNDSSON\"],\"53.33306_-6.24889\":[\"DIAS: Dublin Institute for Advanced Studies  (Dublin - Ireland) - Contact: Dr. Martin M\\u00f6llhoff\"],\"31.87808_34.73983\":[\"NDC: National Data Center of Israel, Soreq Nuclear Research Center (Yavne - Israel) - Contact: Dr. Y. RADZYNER\"],\"31.76904_35.21633\":[\"GSI: Geological Survey of Israel  (Jerusalem - Israel) - Contact: \\tDr Ran NOF\"],\"45.64953_13.77678\":[\"OGS: Istituto Nazionale di Oceanografia e Geofisica Sperimentale (Trieste - Italy) - Contact: Pr. S. PAROLAI\"],\"31.95522_35.94503\":[\"JSO: Jordan Seismological Observatory (Amman - Jordan) - Contact: Ghassan SWEIDAN\"],\"42.67272_21.16688\":[\"GSK: Seismological Institute of Kosovo (Pristina - Kosovo) - Contact: \\tM. M. SHEMSI\"],\"33.89332_35.50157\":[\"SGB: Geophysics Centre at Bhannes  (Beirut - Lebanon) - Contact: \\tDr. M. BRAX\"],\"32.88743_13.18733\":[\"LCRSSS: Libyan Center for Remote Sensing and Space Science  (Tripoli - Libya) - Contact: Dr. A. ELMELADE\"],\"49.61167_6.13\":[\"ECGS: European Center for Geodynamics and Seismology  (Luxembourg - Luxembourg) - Contact: Dr. A. OTH\"],\"35.89968_14.5148\":[\"UM: Department, University of Malta  (Valletta - Malta) - Contact: \\tDr. P. GALEA\"],\"47.00556_28.8575\":[\"ASM-CIP: Academy of Sciences of Republic of Moldova (Chisinau - Moldova) - Contact: Dr. I. NICOARA\"],\"43.73333_7.41667\":[\"Direction de l'Environnement (Monaco - Monaco) - Contact: Ms J. ASTIER\"],\"42.44111_19.26361\":[\"MSO: Institute of Hydrometeorology and Seismology  (Podgorica - Montenegro) - Contact: MSc J. MIHALJEVIC\"],\"34.01325_-6.83255\":[\"D\\u00e9partement des Sciences de la Terre (Rabat - Morocco) - Contact: Dr. Y. TIMOULALI\",\"CNRST: Centre National pour la Recherche Scientifique et Technique  (Rabat - Morocco) - Contact: J. NACER\"],\"52.37403_4.88969\":[\"KNMI: Royal Netherlands Meteorological Institute  (Amsterdam - Netherlands) - Contact: Dr. R. SLEEMAN\"],\"41.99646_21.43141\":[\"SKO: Seismological Observatory (Skopje - North Macedonia) - Contact: Dr. D. CERNIH\"],\"59.95597_11.04918\":[\"NORSAR: Norwegian Seismic Array  (Lillestrom - Norway) - Contact: \\tDr. J. SCHWEITZER\"],\"60.39299_5.32415\":[\"BER: University of Bergen  (Bergen - Norway) - Contact: \\tDr. L. OTTEMOLLER\"],\"52.22977_21.01178\":[\"IGPAS: Institute of Geophysics, Polish Academy of Sciences  (Warsaw - Poland) - Contact: L. RUDZINSKI\"],\"38.71667_-9.13333\":[\"Faculdade de Ci\\u00eancias da Universidade de Lisboa (Lisbon - Portugal) - Contact: C. CORELA\",\"IMP: Instituto de Meteorologia  (Lisbon - Portugal) - Contact: Dr. F. CARRILHO\"],\"38.56667_-7.9\":[\"Universidade de Evora (\\u00c9vora - Portugal) - Contact: Dr. M. BEZZEGHOUD\"],\"44.43225_26.10626\":[\"NIEP: National Institute for Earth Physics  (Bucharest - Romania) - Contact: Dr. C. IONESCU\"],\"55.75222_37.61556\":[\"GSRAS: Geophysical Survey of the Russian Academy of Sciences  (Moscow - Russia) - Contact: Dr. A. MALOVICHKO\"],\"44.80401_20.46513\":[\"SSS: Seismological Survey of Serbia  (Belgrade - Serbia) - Contact: DEJAN VALCIC\"],\"48.14816_17.10674\":[\"ESI SAS: Earth Science Institute, SAS, Department of Seismology (Bratislava - Slovakia) - Contact: Dr. A. CIPCIAR\"],\"46.05108_14.50513\":[\"ARSO: Agencija Republike Slovenije za okolje  (Ljubljana - Slovenia) - Contact: \\tDr. I. CECIC\"],\"41.38879_2.15899\":[\"ICGC: Institut Cartografic i Geologic de Catalunya  (Barcelona - Spain) - Contact: \\tJ. ANTONIO JARA\"],\"59.85882_17.63889\":[\"SNSN: Swedish National Seismic Network  (Uppsala - Sweden) - Contact: B. LUND\"],\"47.36667_8.55\":[\"ETH: Schweizerischer Erdbebendienst  (Zurich - Switzerland) - Contact: Dr. J. Clinton\"],\"36.81897_10.16579\":[\"INMT: Institut National de la M\\u00e9t\\u00e9orologie  (Tunis - Tunisia) - Contact: Dr. S. B. ABDALLAH\"],\"41.01384_28.94966\":[\"KOERI: Kandilli Observatory and Earthquake Research Institute  (Istanbul - Turkey) - Contact: Prof. H. OZENER\"],\"39.91987_32.85427\":[\"ERD: Disaster and Emergency Management Presidency, Earthquake Department  (Ankara - Turkey) - Contact: Fatih ALVER\"],\"50.45466_30.5238\":[\"MCSM: Main Centre for Special Monitoring  (Kyiv - Ukraine) - Contact: M. A. LIASHCHUK\"],\"24.45118_54.39696\":[\"Dubai Municipality (Abu Dhabi - United Arab Emirates) - Contact: Mrs. E. A. AL KHATIBI\"],\"55.9125357_-3.3151365\":[\"BGS: British Geological Survey  (Edinburgh - United Kingdom) - Contact: M. SEGOU\"],\"15.35472_44.20667\":[\"NSOC: National Seismological Observatory Centre  (Sanaa - Yemen) - Contact: Dr. J. M. SHOLAN\"]},\"nodal\":{\"48.69572_2.18727\":[\"LDG: Laboratoire de D\\u00e9tection et de G\\u00e9ophysique  (Arpajon - France) - Contact: Dr. H. HEBERT\"],\"52.24437_13.041053\":[\"GFZ: GeoForschungsZentrum  (Berlin - Germany) - Contact: Dr. J. SAUL\"],\"45.46427_9.18951\":[\"INGV: Istituto Nazionale di Geofisica e Vulcanologia  (Milan - Italy) - Contact: Dr. M. LOCATI\"],\"41.89193_12.51133\":[\"INGV: Istituto Nazionale di Geofisica e Vulcanologia  (Rome - Italy) - Contact: L. SCOGNAMIGLIO\"],\"40.4165_-3.70256\":[\"IGN: Instituto Geografico Nacional  (Madrid - Spain) - Contact: J. V. CANTAVELLO NADAL\"]},\"rights\":{\"52.09083_5.12222\":[\"ORFEUS: Observatories and Research Facilities for EUropean Seismology  (Utrecht - Netherlands) - Contact: C. CAUZZI\"],\"46.20222_6.14569\":[\"ESC: European Seismological Commission  (Geneve - Switzerland) - Contact: Dr. A. OTH\"],\"51.3960409_-1.2377428\":[\"ISC: International Seismological Centre  (Thatcham - United Kingdom) - Contact: Dr. D. STORCHAK\"],\"38.89511_-77.03637\":[\"USGS: U.S. Geological Survey  (Washington - United States) - Contact: \\tM. P. EARLE\"]}}}; </script><div class=\"quacc\">\n",
       "<div class=\"quacclab\">EMSC members</div>\n",
       "<div>The EMSC is an international, non-profit NGO composed of more than 70 member institutes around the world. We operate a system for rapid collection, determination, and dissemination of earthquake parameters using seismic data contributed by seismological institutes together with crowdsourced data from earthquake eyewitnesses. Learn more about  \n",
       "        <a href=\"/about_us/who_we_are/\" rel=\"noopener\" style=\"text-decoration: underline;\" target=\"_blank\">who we are</a> and <a href=\"/about_us/what_we_do/\" rel=\"noopener\" style=\"text-decoration: underline;\" target=\"_blank\">what we do</a>. </div>\n",
       "<br/>\n",
       "<div id=\"map_emsc_members\"></div>\n",
       "</div></div><div class=\"hright\"><div class=\"hmap\" id=\"hmap\"></div><div class=\"home_t2 ht20\">Latest earthquakes</div><div class=\"home_t2 t2_hfe\"><span class=\"feltbt\"><span class=\"hfe\"><span class=\"bg-HOME bg-HOME_felt_button\"></span></span>\n",
       "<span class=\"hfe home_felt\">I felt an earthquake</span></span></div><div class=\"htab\"><table class=\"eqs table-scroll\">\n",
       "<thead><tr><th class=\"thico\"></th><th class=\"citiz\" colspan=\"2\"><div>Citizen<br/>response</div><div><div class=\"dm comm\"></div><div class=\"dm pic\"></div></div></th>\n",
       "<th class=\"tbdat\">Date &amp; Time<div>UTC</div></th><th class=\"tblat\">Lat.<div>degrees</div></th><th class=\"tblon\">Lon.<div>degrees</div></th><th class=\"tbdep\">Depth<div>km</div></th><th class=\"tbmag\">Mag.</th><th class=\"tbreg\">Region</th></tr></thead>\n",
       "<tbody></tbody>\n",
       "</table>\n",
       "</div><div class=\"hright2\"><b>Bold : Earthquakes with a magnitude ≥ 4.5 in Euro-med, or ≥ 5.5 in the world </b><br><b style=\"color:red;\">Red : Earthquakes with a magnitude ≥ 5.0 in Euro-med, or ≥ 6.0 in the world </b><br/></br></div></div><div style=\"clear:both;\"></div><script> console.log(\"TimeLoad\",0.006208896637); </script></div><div class=\"footer\"><div class=\"foot-cont\"><div class=\"part\"><div class=\"foot-logo-label\">EMSC is the European infrastructure for seismological products in</div><a aria-label=\"epos\" href=\"https://www.epos-eu.org/\" target=\"_blank\"><div class=\"spe foot-logo\"></div></a></div><div class=\"part2\"><div class=\"part-middle\"><a href=\"/faq/\">FAQ</a><a class=\"privacy\" href=\"/privacy/index.php\">© 2023 - privacy</a><a href=\"/contact/\">Contact us</a></div></div><div class=\"part p-soc\"><a aria-label=\"facebook EMSC.CSEM\" href=\"https://www.facebook.com/EMSC.CSEM/\" target=\"_blank\"><span class=\"spe f-facebook\"></span></a><a aria-label=\"twitter lastquake\" href=\"https://twitter.com/lastquake\" target=\"_blank\"><span class=\"spe f-twitter\"></span></a><a aria-label=\"linkedin emsc-csem\" href=\"https://www.linkedin.com/company/emsc-csem/\" target=\"_blank\"><span class=\"spe f-linkedin\"></span></a><a aria-label=\"youtube EuroMSC\" href=\"https://www.youtube.com/user/EuroMSC\" target=\"_blank\"><span class=\"spe f-youtube\"></span></a></div></div></div></body></html>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "#url7 = 'https://www.emsc-csem.org/Earthquake/'\n",
    "url7 = \"https://www.emsc-csem.org/#2\"\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "terr = requests.get(url7)\n",
    "soup7 = BeautifulSoup(terr.content, \"html.parser\")\n",
    "soup7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lista para almacenar los datos de los terremotos\n",
    "terremotos = []\n",
    "\n",
    "# Encontrar la tabla que contiene los datos de los terremotos\n",
    "tabla = soup7.find('table', class_='eqs')\n",
    "\n",
    "# Extraer filas de la tabla\n",
    "filas = tabla.find_all('tr')\n",
    "\n",
    "# Recorrer filas y extraer los datos\n",
    "for fila in filas:  \n",
    "    columnas = fila.find_all('td')\n",
    "    if len(columnas) >= 11:  # Asegurar que hay suficientes columnas\n",
    "        fecha_hora = columnas[3].text.strip()\n",
    "        latitud = columnas[4].text.strip()\n",
    "        longitud = columnas[5].text.strip()\n",
    "        region = columnas[9].text.strip()\n",
    "    \n",
    "        terremotos.append({\n",
    "         'Fecha y hora': fecha_hora,\n",
    "         'Latitud': latitud,\n",
    "         'Longitud': longitud,\n",
    "         'Región': region\n",
    "        })\n",
    "\n",
    "print(terremotos)\n",
    "\n",
    "# df_terremotos = pd.DataFrame(terremotos)\n",
    "\n",
    "# print(df_terremotos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 11 - Datos del Top 250 de IMDB (nombre de la película, lanzamiento inicial, nombre del director y estrellas) como un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>403 Forbidden</title></head>\n",
       "<body>\n",
       "<center><h1>403 Forbidden</h1></center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url11 = 'https://www.imdb.com/chart/top'\n",
    "pelis = requests.get(url11)\n",
    "soup11 = BeautifulSoup(pelis.content,\"html.parser\")\n",
    "soup11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tabla_peliculas \u001b[38;5;241m=\u001b[39m soup11\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipc-metadata-list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extraer filas de la tabla\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m filas \u001b[38;5;241m=\u001b[39m tabla_peliculas\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Recorrer filas y extraer los datos\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fila \u001b[38;5;129;01min\u001b[39;00m filas:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lista para almacenar los datos de las películas\n",
    "peliculas_data = []\n",
    "\n",
    "# Encontrar la tabla que contiene los datos de las películas\n",
    "tabla_peliculas = soup11.find('ul', class_='ipc-metadata-list')\n",
    "\n",
    "# Extraer filas de la tabla\n",
    "filas = tabla_peliculas.find_all('li')[1:]\n",
    "\n",
    "# Recorrer filas y extraer los datos\n",
    "for fila in filas:\n",
    "    nombre = fila.find('td', class_='titleColumn').a.text\n",
    "    lanzamiento = fila.find('span', class_='secondaryInfo').text.strip('()')\n",
    "    director_estrellas = fila.find('td', class_='titleColumn').a['title'].split(', ')\n",
    "    director = director_estrellas[0].replace(' (dir.)', '')\n",
    "    estrellas = ', '.join(director_estrellas[1:])\n",
    "    \n",
    "    peliculas_data.append({\n",
    "        'Nombre': nombre,\n",
    "        'Lanzamiento': lanzamiento,\n",
    "        'Director': director,\n",
    "        'Estrellas': estrellas\n",
    "    })\n",
    "\n",
    "df_peliculas = pd.DataFrame(peliculas_data)\n",
    "\n",
    "print(df_peliculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 12 - Nombre de la película, año y un breve resumen de las 10 películas aleatorias top (IMDB) como un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(soup.find_all(\"span\", {\"class\": \"secondaryInfo\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 13 - Encontrar el reporte meteorológico en vivo (temperatura, velocidad del viento, descripción y clima) de una ciudad dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current  ### fALTA api KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(city):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafío 14 - Nombre del libro, precio y disponibilidad de stock como un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This is the url you will scrape in this exercise. \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# It is a fictional bookstore created to be scraped. \u001b[39;00m\n\u001b[0;32m      3\u001b[0m url14 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://books.toscrape.com/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m books \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url11)\n\u001b[0;32m      5\u001b[0m soup14 \u001b[38;5;241m=\u001b[39m BeautifulSoup(books\u001b[38;5;241m.\u001b[39mcontent,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url14 = 'http://books.toscrape.com/'\n",
    "books = requests.get(url11)\n",
    "soup14 = BeautifulSoup(books.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libros = list(soup.select('h1.h3 a[title]'))\n",
    "# #nombres = soup.select('h1.h3 a[tittle]')\n",
    "# libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup14' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m disponibilidades \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Encontrar todos los contenedores de libros\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m libros_html \u001b[38;5;241m=\u001b[39m soup14\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_pod\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Recorrer los contenedores y extraer los datos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m libro_html \u001b[38;5;129;01min\u001b[39;00m libros_html:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Obtener nombre del libro\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'soup14' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Listas para almacenar los datos de los libros\n",
    "libros = []\n",
    "precios = []\n",
    "disponibilidades = []\n",
    "\n",
    "# Encontrar todos los contenedores de libros\n",
    "libros_html = soup14.find_all('article', class_='product_pod')\n",
    "\n",
    "# Recorrer los contenedores y extraer los datos\n",
    "for libro_html in libros_html:\n",
    "    # Obtener nombre del libro\n",
    "    nombre = libro_html.get_text(strip=True)\n",
    "    libros.append(nombre)\n",
    "    \n",
    "    # Obtener precio del libro\n",
    "    precio = libro_html.find('p', class_='price_color').text\n",
    "    precios.append(precio)\n",
    "    \n",
    "    # Obtener disponibilidad del libro\n",
    "    disponibilidad = libro_html.find('p', class_='instock').text.strip()\n",
    "    disponibilidades.append(disponibilidad)\n",
    "\n",
    "df_libros = pd.DataFrame({\n",
    "    'Nombre': libros,\n",
    "    'Precio': precios,\n",
    "    'Disponibilidad': disponibilidades\n",
    "})\n",
    "\n",
    "print(df_libros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitates tu output? Gracias! 🙂**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
