{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de evaluación de modelos de aprendizaje supervisado\n",
    "\n",
    "Realice los siguientes ejercicios para consolidar sus conocimientos y comprensión de la evaluación de modelos de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de modelos de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL del dataset de Boston hoyusing data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "\n",
    "# Nombres de las columnas\n",
    "column_names = [\n",
    "    \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\",\n",
    "    \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"\n",
    "]\n",
    "\n",
    "# Cargar el dataset en un DataFrame\n",
    "data = pd.read_csv(url, delim_whitespace=True, header=None, names=column_names)\n",
    "\n",
    "X = data.drop(\"MEDV\", axis=1)\n",
    "y = data[\"MEDV\"]\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Divida este conjunto de datos en conjuntos de train (80%) y de test (20%).\n",
    "\n",
    "El campo `MEDV` representa el valor medio de las viviendas ocupadas por sus propietarios (en miles de dólares) y es la variable objetivo que queremos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, f1_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data.drop(\"MEDV\", axis=1)\n",
    "# y = data[\"MEDV\"] -> Objetivo\n",
    "\n",
    "# Dividir conjunto de datos con train_test_split en datos entrenamiento/prueba (80%/20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31071989)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrene un modelo `LinearRegression` en este conjunto de datos y genere predicciones tanto en el conjunto de entrenamiento como en el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Modelo Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones entrenamiento\n",
    "y_pred_train= model.predict(X_train)\n",
    "\n",
    "# Predicciones Pruebas\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calcule e imprima R-cuadrado tanto para el conjunto de entrenamiento como para el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score Train: 0.7452254954385831 vs R2 Score Test: 0.7072549575355775\n"
     ]
    }
   ],
   "source": [
    "# Métricas (mean_squared_error, r2_score, mean_absolute_error)\n",
    "\n",
    "## Entrenamiento\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "## Test\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"R2 Score Train: {r2_train} vs R2 Score Test: {r2_test}\")\n",
    "# VARIABILIDAD (0-1, más cerca de 1 mejor ajuste): R2 Score Train: 0.7452254954385831 vs R2 Score Test: 0.7072549575355775\n",
    "# Buen ajuste, ligeramente superior para datos entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calcule e imprima el error cuadrático medio para el conjunto de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 21.798899395961175 vs MSE Test: 23.366454865016184\n"
     ]
    }
   ],
   "source": [
    "## Entrenamiento\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "## Test\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MSE Train: {mse_train} vs MSE Test: {mse_test}\")\n",
    "# PROMEDIO ERRORES CUADRADOS (Más bajo = mejor ajuste, penaliza errores grandes)\n",
    "# Buen ajuste, ligeramente superior para datos entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calcule e imprima el error medio absoluto para el conjunto de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaE Train: 3.2760151541092073 vs MaE Test: 3.5309236021086723\n"
     ]
    }
   ],
   "source": [
    "## Entrenamiento\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "## Test\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MaE Train: {mae_train} vs MaE Test: {mae_test}\")\n",
    "# PROMEDIO ERRORES ABSOLUTOS (Más bajo = mejor precisión, medida magnitud error): \n",
    "# La predicción se desvía en 3.28 mil $ en entrenamiento y 3.53 mil $ en test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X_c = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y_c = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "datac = pd.concat([X_c, y_c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Divida este conjunto de datos en conjuntos de train (80%) y de test (20%).\n",
    "\n",
    "El campo `class` representa el tipo de flor y es la variable objetivo que querremos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y_c = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_c, y_c, test_size=0.2, random_state=31071989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\az14o\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\az14o\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,8))\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "sns.set(rc={'figure.figsize':(6,6)});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrene un modelo `LogisticRegression` en este conjunto de datos y genere predicciones tanto en el conjunto de entrenamiento como en el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000) # Dejo que escoja el solver más adecuado automáticamente + entrenar el modelo 1000 veces\n",
    "model.fit(X_train, y_train.values.ravel()) # Aplanamos para evitar ValueError: Found input variables with inconsistent numbers of samples: [30, 120]\n",
    "\n",
    "\n",
    "# Predicciones entrenamiento\n",
    "y_pred_train= model.predict(X_train)\n",
    "\n",
    "# Predicciones Pruebas\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calcule e imprima la puntuación de precisión tanto para el conjunto de entrenamiento como para el de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Esta función resuelve los ejercicios 8,9,10,11,12 y 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.95\n",
      "Test Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Métricas (accuracy_score, balanced_accuracy_score, precision_score, f1_score, recall_score, confusion_matrix)\n",
    "# PRECISIÓN / ACCURACY : Tasa de acierto total\n",
    "\n",
    "## Entrenamiento\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "\n",
    "## Test\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# El modelo ha clasificado correctamente el 95% de las muestras de entrenamoiento y el 96,6% de las de test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calcule e imprima la puntuación de precisión equilibrada tanto para el conjunto de entrenamiento como para el de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Balanced Accuracy: 0.94804318488529\n",
      "Test Balanced Accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "# PRECISIÓN EQUILIBRADA / BALANCED ACCURACY  Tasa de acierto por clase\n",
    "train_balanced_accuracy = balanced_accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Train Balanced Accuracy: {train_balanced_accuracy}\")\n",
    "\n",
    "test_balanced_accuracy = balanced_accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Balanced Accuracy: {test_balanced_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calcule e imprima la puntuación de precisión tanto para el conjunto de entrenamiento como para el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.95\n",
      "Test Precision: 0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "# PRECISION\n",
    "train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
    "print(f\"Train Precision: {train_precision}\")\n",
    "\n",
    "test_precision = precision_score(y_test, y_pred_test, average='weighted')\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calcule e imprima la puntuación de recuerdo tanto para el conjunto de entrenamiento como para el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.95\n",
      "Test Recall: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# RECALL\n",
    "train_recall = recall_score(y_train, y_pred_train, average='weighted')\n",
    "print(f\"Train Recall: {train_recall}\")\n",
    "\n",
    "test_recall = recall_score(y_test, y_pred_test, average='weighted')\n",
    "print(f\"Test Recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calcule e imprima la puntuación F1 tanto para el conjunto de entrenamiento como para el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 Score: 0.95\n",
      "Test F1 Score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
    "print(f\"Train F1 Score: {train_f1}\")\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred_test ,average='weighted')\n",
    "print(f\"Test F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generar matrices de confusión tanto para el conjunto de entrenamiento como para el de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix:\n",
      "[[43  0  0]\n",
      " [ 0 36  3]\n",
      " [ 0  3 35]]\n",
      "Test Confusion Matrix:\n",
      "[[ 7  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "train_confusion_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(f\"Train Confusion Matrix:\\n{train_confusion_matrix}\")\n",
    "\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"Test Confusion Matrix:\\n{test_confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte Test: =               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.92      0.92      0.92        39\n",
      "           2       0.92      0.92      0.92        38\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.95      0.95      0.95       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n",
      "Reporte Test: =               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" REPORTE : \"\"\"\n",
    "from sklearn.metrics import classification_report\n",
    "reporte_train = classification_report(y_train, y_pred_train)\n",
    "print(f\"Reporte Test: = {reporte_train}\")\n",
    "\n",
    "reporte_test = classification_report(y_test, y_pred_test)\n",
    "print(f\"Reporte Test: = {reporte_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Para cada uno de los conjuntos de datos de este laboratorio, intente entrenar con algunos de los otros modelos que ha aprendido, vuelva a calcular las métricas de evaluación y compare para determinar qué modelos funcionan mejor en cada conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression, Precisión Media: 0.97, Desviación Estándar: 0.02\n",
      "Modelo: Decision Tree Classifier, Precisión Media: 0.96, Desviación Estándar: 0.03\n",
      "Modelo: Random Forest Classifier, Precisión Media: 0.96, Desviación Estándar: 0.02\n",
      "Modelo: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Modelo: Decision Tree Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Modelo: Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.85      1.00      0.92        11\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.95      0.94      0.94        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score # Validación cruzada\n",
    "\n",
    "X_c = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y_c = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_c, y_c, test_size=0.2, random_state=31071989)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "for nombre, modelo in models.items(): # Validación cruzada\n",
    "    scores = cross_val_score(modelo, X_c, y_c.values.ravel(), cv=5, scoring='accuracy')\n",
    "    print(f\"Modelo: {nombre}, Precisión Media: {scores.mean():.2f}, Desviación Estándar: {scores.std():.2f}\")\n",
    "\n",
    "\n",
    "reportes = []\n",
    "for nombre, modelo in models.items():\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    reporte = f\"Modelo: {nombre}\\n{classification_report(y_test, y_pred)}\"\n",
    "    reportes.append(reporte)\n",
    "\n",
    "# print(reportes)\n",
    "for reporte in reportes:\n",
    "    print(f\"{reporte}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
